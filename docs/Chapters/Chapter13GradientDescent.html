
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Gradient Descent &#8212; Operations Research OER</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Classification" href="Chapter12Classification.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/JuliaSetECUColors.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Operations Research OER</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   Introduction to Operations Research
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter01Modeling.html">
   Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter02LinearProgramming.html">
   Linear Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter03SimplexMethod.html">
   Simplex Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter04GoalProgramming.html">
   Goal Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter05NetworkModels.html">
   Network Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter06Transport.html">
   Transportation Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter07Queuing.html">
   Queuing Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter09DynamicProgramming.html">
   Dynamic Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter10GameTheory.html">
   Game Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter11MonteCarlo.html">
   Monte Carlo Simulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter12Classification.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Gradient Descent
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Chapters/Chapter13GradientDescent.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/nurfnick/Operations_Research"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/nurfnick/Operations_Research/issues/new?title=Issue%20on%20page%20%2FChapters/Chapter13GradientDescent.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/nurfnick/Operations_Research/master?urlpath=tree/Chapters/Chapter13GradientDescent.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/nurfnick/Operations_Research/blob/master/Chapters/Chapter13GradientDescent.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#theory-of-gradient-descent">
     Theory of Gradient Descent
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#figure-2-mini-batch-gradient-descent">
       Figure 2: Mini-batch gradient descent
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mountain-climbing-visualization">
     Mountain climbing visualization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#figure-3-mountain-visualization">
       Figure 3: Mountain visualization
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finding-the-gradient-descent-in-more-detail">
   Finding the Gradient Descent in more detail
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problems">
   Problems
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#authors">
     Authors
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="gradient-descent">
<h1>Gradient Descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Gradient descent is an optimization aglorithm that is used for one thing: finding the local minimum of the differentiable function. How we are able to find that is once we find a spot of the function’s gradient, we need to repeat the steps until we eventually get to the functions local minumum.</p>
<p>This algorithm was first introduced to the world by Augustin-Louis Cauchy back in the year of 1847. He created this algorithm to help solve larger optimization problems in a short amount of time that were used in studying astrology. Although it’s still used in astrology today, we also use it in our daily live’s without realizing that we are using gradient descent.</p>
<p>For example, when students are going to class we need to find the quickest way to class. Also when we are driving, we are wanting to get to our desination the quickest so we can save our time and gas. When it comes to making huge purchases in life, like a vehicle. Once we know what vehicle that we want to purchase, we usually travel to different dealerships to find that vehicle with the cheapest price.</p>
<p><img alt="Image of Gradient Descent .png" src="https://raw.githubusercontent.com/nurfnick/Operations_Research/main/Drafts/Gradient%20Descent/GDImg/GDImg1.png" /></p>
<h6> Figure 1: Visualization of gradient descent <h6><div class="section" id="theory-of-gradient-descent">
<h3>Theory of Gradient Descent<a class="headerlink" href="#theory-of-gradient-descent" title="Permalink to this headline">¶</a></h3>
<p>While gradient descent is the main section that we will be talking about in this section,there are different types of gradient descent. There’s three types of algorithms: batch, socratic, and mini-batch gradient descent. While these are all of the gradient descent algorithm categories,they are used for different categories.</p>
<ol class="simple">
<li><p><strong>Batch Gradient Descent</strong> - It calculates the error of each example in the dataset but only after all of the training values have been evaluated and the model has been upgraded. This type is great for producing a stable error and convergience.</p></li>
<li><p><strong>Socratic Gradient Descent</strong> - This is used within the dataset. In other words, its updates the parameters for each example one-by-one. Depending on the problem, socratic gradient descent can be quicker than the batch.</p></li>
<li><p><strong>Mini-Batch Gradient Descent</strong> - This version is a mixture of both batch and socratic gradient descent. It is the go-to method because it simply splits the training data into small batches and performs an update for every batch. This type is the most common type of gradient descent.</p></li>
</ol>
<p>When it comes to finding the gradient descent of a function, we need to understand what we are trying to find. When you try to calculate the gradient descent, the student needs to follow the negative slope of the objective function in order to locate the minimum of the function. The minimum is also known as the <strong>cost</strong>.</p>
<p>When it’s a positive slope then it’s a minimum, when it’s a negative slope, then it’s the maximum.</p>
<p><img alt="Mini-Batch GD.png" src="https://raw.githubusercontent.com/nurfnick/Operations_Research/main/Drafts/Gradient%20Descent/GDImg/GDImg2.png" /></p>
<div class="section" id="figure-2-mini-batch-gradient-descent">
<h4>Figure 2: Mini-batch gradient descent<a class="headerlink" href="#figure-2-mini-batch-gradient-descent" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="mountain-climbing-visualization">
<h3>Mountain climbing visualization<a class="headerlink" href="#mountain-climbing-visualization" title="Permalink to this headline">¶</a></h3>
<p>Let’s say that someone is trying to walk down a mountain the quickest way possible. The person can’t go straight down because that’s impossible. In order to get to the bottom, we need to take different stops to get to the bottom. The figure below shows a visualization of the statement above.</p>
<p><img alt="Screen Shot 2021-10-26 at 6.52.48 PM.png" src="https://raw.githubusercontent.com/nurfnick/Operations_Research/main/Drafts/Gradient%20Descent/GDImg/GDImg3.png" /></p>
<div class="section" id="figure-3-mountain-visualization">
<h4>Figure 3: Mountain visualization<a class="headerlink" href="#figure-3-mountain-visualization" title="Permalink to this headline">¶</a></h4>
<p>Below is an example is the pseducode of the mountain example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># x and y coordinates of the mountain</span>
<span class="n">mountain_x</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">]</span>
<span class="n">mountain_y</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># x and y stop coordinates</span>
<span class="n">stop_x</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">7.5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">7.5</span><span class="p">]</span>
<span class="n">stop_y</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>

<span class="c1">#plotting the mountain, stops, and path</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mountain_x</span><span class="p">,</span><span class="n">mountain_y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">stop_x</span><span class="p">,</span><span class="n">stop_y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">stop_x</span><span class="p">,</span><span class="n">stop_y</span><span class="p">)</span>

<span class="c1">#visualize the grid </span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Chapter13GradientDescent_7_0.png" src="../_images/Chapter13GradientDescent_7_0.png" />
</div>
</div>
<p>Here, consider the loss_function() which is a global minimum (x1) and several local minima.</p>
</div>
</div>
</div>
<div class="section" id="finding-the-gradient-descent-in-more-detail">
<h2>Finding the Gradient Descent in more detail<a class="headerlink" href="#finding-the-gradient-descent-in-more-detail" title="Permalink to this headline">¶</a></h2>
<h6>Below we have an example that goes more indepth with the gradient descent algorithm<h6><p>Let’s say that we are trying to find someone peoples weight and height. Here are the following x is the weight and y is the height.</p>
<p>1.(0.5 , 1.4)</p>
<p>2.(2.3 , 1.9)</p>
<p>3.(2.9 ,3.2)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Graph that Shows the Above Points</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">xpoints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span> <span class="p">,</span> <span class="mf">2.3</span> <span class="p">,</span> <span class="mf">2.9</span><span class="p">])</span>
<span class="n">ypoints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.4</span> <span class="p">,</span> <span class="mf">1.9</span> <span class="p">,</span> <span class="mf">3.2</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xpoints</span><span class="p">,</span> <span class="n">ypoints</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Chapter13GradientDescent_11_0.png" src="../_images/Chapter13GradientDescent_11_0.png" />
</div>
</div>
<p>With this algorithm we are able to predict their height with a simple equation:</p>
<p><strong>Predicted Height = intercept + slope x weight</strong></p>
<p>To solve the problem we should do the following:</p>
<ol class="simple">
<li><p>Start by using GD to find the intercept.</p></li>
<li><p>Then we will use GD to solve the Intercept and the Slope.</p></li>
<li><p>We plug can plug any number in the Least Squares section. We chose 0.64.</p></li>
<li><p>Since we need to find the intercept, pick any number for the intercept and plug it in (for this example, let’s pick 0).</p></li>
<li><p>We need to plug in the x-value into the weight function.</p></li>
</ol>
<p>When we complete those steps, our equation should look like and we can find the Predicted Height:</p>
<p><strong>Predicted Height = 0 + 0.64 * 0.5</strong></p>
<p>Once we got the Predicted Height, we need to calculate the difference between the Observed and Predicted Height. The Observed Height is the y value of the coordinates of the points from above.</p>
<p>When we find the Predicted Height, we can now find the differences between all of the Observed and Predicted Height. The Observed Height is the y-value.</p>
<p>When we find all of the Predicted Heights, we can finally find the Sum of the Squared Residuals.</p>
<p>We find this by squaring the Sum of the Squared Residuals.</p>
<p><strong>NOTE: We can now plug in any value for the Intercept and get a new Predicted Height</strong></p>
<p>The example below shows where you should plug the number to solve to get the next answer:</p>
<p>For the next person it’ll be:</p>
<p><strong>(1.9 - (intercept + 0.64 x 2.3))^2</strong></p>
<p>The last persons equation will be:</p>
<p><strong>(3.2 - (intercept + 0.64 x 2.9))^2</strong></p>
<p>We now have an equation for the curve and we will need to find the derivative of the function.</p>
<p>Now we need to find the derivative of the sum of the squared residuals.</p>
<p>The equation that we use is:</p>
<blockquote>
<div><p><strong>(d/d intercept) Sum of squared residuals</strong></p>
</div></blockquote>
<p>We need to apply the change rule, once we do that, we will get the following:</p>
<blockquote>
<div><p><strong>-2(1.4-Intercept+0.64x0.5)+-2(1.9-Intercept+0.64x2.3))+-2(3.2-Intercept+0.64x2.9))</strong></p>
</div></blockquote>
<p>Now gradient descent will use it to find where the Sum of the Squared Residuals is the lowest.</p>
<p>Since we have the step size, we can calculate a new intercept:</p>
<p><strong>NEW INTERCEPT = OLD INTERCEPT - STEP SIZE</strong></p>
<p>To see how much the residuals shrink when the intercept we need to plug in 0.57 into the chain rule problem above:</p>
<p><strong>STEP SIZE = -2.3 x LEARNING RATE</strong>
<strong>STEP SIZE = -2.3 x 0.1 -&gt; -0.23</strong>
<strong>NEW INTERCEPT = 0.57 - (-0.23) -&gt; 0.8 NEW INTERCEPT</strong></p>
<p>Now we need to <strong>go back to the derivative equation from earlier and plug in the 0.8</strong> now
<strong>-2(1.4-(0.8+0.64x0.5) + -2(1.9-(0.8+0.64x0.5))+-2(3.2-(0.8+0.64x2.9))</strong> -&gt; -0.9</p>
<p>the new step size is now -0.9 * 0.1 = -0.09
new intercept is 0.89
when we do it again, the new intercept is 0.92</p>
<p><strong>When we do this 6 times, the Gradient Descent for the intercept is 0.95 because the Gradient Descent gets as close to 0 as possible</strong>.</p>
<p><strong>Summary:</strong></p>
<hr class="docutils" />
<ol class="simple">
<li><p>Take the derivative of the Loss Function for each parameter in it.</p></li>
<li><p>Pick random values for the parameters.</p></li>
<li><p>Plug the paramenter values into the derivatives, which is the Gradient.</p></li>
<li><p>Calculate the Step Sizes: Step Size = Slope * Learning Rate.</p></li>
<li><p>Calculate the New Parameters (e.g. intercept): New Parameter = Old Parameter - Step Size.</p></li>
<li><p>Go back to step 3 and repeat the Step Size is very small, or when the Maximum Number of Steps is reached.</p></li>
</ol>
<p>##Find the gradient descent of <span class="math notranslate nohighlight">\(y=(x+5)^2\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Gradient Descent example graph</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">derf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">5</span><span class="p">)</span>
<span class="n">i</span><span class="o">=</span><span class="mi">3</span>
<span class="n">w</span><span class="o">=</span><span class="mf">0.05</span>
<span class="n">x</span><span class="o">=</span><span class="n">i</span>

<span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">-</span><span class="n">weight</span><span class="o">*</span><span class="n">derf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">0.00004</span><span class="p">)</span>
<span class="n">Y</span><span class="o">=</span><span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>

<span class="n">X1</span><span class="o">=</span><span class="p">[]</span>

<span class="n">y1</span><span class="o">=</span><span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">X1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span><span class="o">=</span><span class="n">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
<img alt="../_images/Chapter13GradientDescent_30_1.png" src="../_images/Chapter13GradientDescent_30_1.png" />
</div>
</div>
<p>##Example 4</p>
<p>In this example, this is how you’d be able to find the gradient descent using a simple pseudocode to find the local minimum of <span class="math notranslate nohighlight">\(f(x) = (x-3)^4\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span><span class="o">**</span><span class="mi">4</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">derf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">4</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="n">i</span><span class="o">=</span><span class="mi">5</span>
<span class="n">w</span><span class="o">=</span><span class="mf">0.05</span> 
<span class="n">x</span><span class="o">=</span><span class="n">i</span>

<span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">-</span><span class="n">weight</span><span class="o">*</span><span class="n">derf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">Y</span><span class="o">=</span><span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>

<span class="n">X1</span><span class="o">=</span><span class="p">[]</span>
<span class="n">y1</span><span class="o">=</span><span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">X1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span><span class="o">=</span><span class="n">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
   
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>16
</pre></div>
</div>
<img alt="../_images/Chapter13GradientDescent_32_1.png" src="../_images/Chapter13GradientDescent_32_1.png" />
</div>
</div>
</div>
<div class="section" id="problems">
<h2>Problems<a class="headerlink" href="#problems" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Find the gradient descent of <span class="math notranslate nohighlight">\(y=(x+3)^4\)</span></p></li>
<li><p>Explain why gradient descent is important.</p></li>
<li><p>How do use gradient descent in our daily lives?</p></li>
<li><p>The function is <span class="math notranslate nohighlight">\(y=(9x+2)^2\)</span>, what is the gradient descent?</p></li>
<li><p>In your own words, describe gradient descent.</p></li>
<li><p>Write a simple code to display the gradient descent of <span class="math notranslate nohighlight">\(y=(x+2)^2\)</span></p></li>
<li><p>Find the gradient descent of <span class="math notranslate nohighlight">\(y=(3x-4)^2\)</span></p></li>
<li><p>What is the gradient descent of <span class="math notranslate nohighlight">\(y=(5x-4)^4\)</span></p></li>
<li><p>Find the gradient descent of <span class="math notranslate nohighlight">\(y=(x-5)^2\)</span></p></li>
<li><p>Give an example of the different types of gradient descent.</p></li>
</ol>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>The gradient descent algorithm is widely used throughout the world. It is used in our daily lives without us realizing what we are using. This algorithm is used to limit the cost of something whether it’s gas being used to get to one place to another. People also use it when they are trying to by a house. For example, they want to purchase a house that has enough square-footage for the best price that is in their budget. Gradient descent is used for nearly anything, this algorithm makes our lives easier.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><strong>Kumari , Ajitesh</strong> “Gradient Descent Explained Simply with Examples.” Data Analytics, <a class="reference external" href="https://vitalflux.com/gradient-descent-explained-simply-with-examples/">https://vitalflux.com/gradient-descent-explained-simply-with-examples/</a>.</p>
<p><strong>Starmer, Josh</strong> Gradient Descent, Step-by-Step - Youtube. <a class="reference external" href="https://www.youtube.com/watch?v=sDv4f4s2SB8">https://www.youtube.com/watch?v=sDv4f4s2SB8</a>.</p>
<p><a class="reference external" href="https://gist.github.com/sagarmainkar/41d135a04d7d3bc4098f0664fe20cf3c">https://gist.github.com/sagarmainkar/41d135a04d7d3bc4098f0664fe20cf3c</a></p>
<p>Gradient descent - introduction and implementation in python. The Math and Python behind AI/Machine Learning. (2019, October 19). Retrieved December 1, 2021, from <a class="reference external" href="https://machinelearningmind.com/2019/10/06/gradient-descent-introduction-and-implementation-in-python/">https://machinelearningmind.com/2019/10/06/gradient-descent-introduction-and-implementation-in-python/</a>.</p>
<div class="section" id="authors">
<h3>Authors<a class="headerlink" href="#authors" title="Permalink to this headline">¶</a></h3>
<p>Principal authors of this chapter were: Maggie Johnson, Kuldeep Gautam, and Pranay Singh</p>
<p>Contributions were made by: Dr. Jacob</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Chapter12Classification.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Classification</p>
        </div>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>